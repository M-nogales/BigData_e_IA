from matplotlib import pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, recall_score, roc_auc_score

# load data
data = pd.read_csv('clientes_marketing.csv')

# features and targets
X = data.drop([ 'Compra'], axis=1)
y = data['Compra']

# split the data between training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# create the decision tree model
model = DecisionTreeClassifier(criterion='gini', max_depth=10,random_state=42)

model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)
y_pred_prob = model.predict_proba(X_test)[:, 1]


# Model evaluation
print("confussion matrix:")
print(confusion_matrix(y_test, y_pred))

accuracy = accuracy_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
auc_roc = roc_auc_score(y_test, y_pred_prob)

# Results
print(f"üîπ Accuracy: {accuracy:.2f}")
print(f"üîπ Recall: {recall:.2f}")
print(f"üîπ F1-Score: {f1:.2f}")
print(f"üîπ AUC-ROC: {auc_roc:.2f}")

# Report
target_names = ['Prob buy', 'Prob no buy']
print("\nClassification Report:\n", classification_report(y_test, y_pred, target_names=target_names))

# Metrics comparation
def metrics_result_comparation(accuracy, recall, f1, auc_roc, model):
    metrics = ['Accuracy', 'Recall', 'F1-Score', 'AUC-ROC']
    values = [accuracy, recall, f1, auc_roc]
    
    # Create a bar chart
    plt.figure(figsize=(8, 6))
    plt.bar(metrics, values, color=['blue', 'green', 'orange', 'red'])
    
    # Add value labels on top of bars
    for i, v in enumerate(values):
        plt.text(i, v + 0.02, f"{v:.2f}", ha='center', fontsize=12, fontweight='bold')
    
    # Labels and title
    plt.ylim(0, 1.1)
    plt.ylabel('Score')
    plt.title('Model Performance Metrics - ' + model)
    plt.grid(axis='y', linestyle='--', alpha=0.7)
    
    # Show the plot
    plt.show()

metrics_result_comparation(accuracy, recall, f1, auc_roc, model = 'Decision Tree')

plt.figure(figsize=(12, 8))
feature_names=["Edad" , "Ingreso_Anual" , "Frecuencia_Visitas" , "Numero_Compras" , "Tiempo_En_Web" , "Compra"]
plot_tree(model, feature_names=feature_names, class_names=target_names, filled=True)
plt.title("√Årbol de Decisi√≥n - Clasificaci√≥n")
plt.show()

# Feature importance
feature_importances = model.feature_importances_
feature_names = X.columns

# Create a DataFrame for visualization
importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')
plt.xlabel('Importance')
plt.title('Feature Importance in Decision Tree')
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.show()

# Print feature importance
print("\nFeature Importances:")
print(importance_df)